### Characterizing participant observations

This is an analysis of the study_observations.xls file that lives in RWJF/Behavioral Phenotyping/Evalutation

```{r, echo=FALSE, warning=FALSE}
library(openxlsx)
library(dplyr)
library(ggplot2)

# load data
P2 <- read.xlsx("observations.xlsx", sheet = 2, colNames = T) %>%
  select(-X1, -X11)
P1 <- read.xlsx("observations.xlsx", sheet = 1, colNames = T)[,colnames(P2)]
P1$patient <- 'P1'
P2$patient <- 'P2'
obs <- rbind(P1, P2)

table(obs$tool)
```

Interestingly, participants generated the same number of observations using the HTML-based and interactive tools (79). 

We can further assess the nature of observations generated by participants:

```{r, echo=FALSE, warning=FALSE}
# comparing the distribution of observationsHTML vs. SHINY
table(obs$tool, obs$type)
chisq.test(obs$tool, obs$type)

ggplot(obs[!is.na(obs$tool) & !is.na(obs$level), ], 
       aes(x = type, fill = tool))+
  geom_histogram(stat="count")+
  ggtitle("Focus of Observation, by Tool")
```

This plot demonstrates that the interactive tool elicited more observations focused on changes in blood glucose, while the HTML-based representation facilitated sense-making of nutritional content. This difference is approaching statistical significance (p = 0.063).

We labeled each observation with more detail:

```{r, echo=FALSE, warning=FALSE}
# remove rows where level == 'n/a'
obs_rm <- obs %>%
  filter(!grepl("n/a", tolower(obs$level)))

ggplot(obs_rm[!is.na(obs_rm$tool) & !is.na(obs_rm$level), ], 
       aes(x = level, fill = level))+
  geom_histogram(stat="count")+
  facet_grid(~tool)+
  ggtitle("Types of Observations Stratified by Tool")

table(obs_rm$tool,obs_rm$level)
```

It is clear that participants were more likely to reason about specific ingredients using the HTML representation. In contrast, the visual analytics tool facilitated reasoning using the macronutrient content of meals. 

### Assessment of statement accuracy

```{r}
ggplot(obs_rm[!is.na(obs_rm$tool) & !is.na(obs_rm$type), ], 
       aes(x = tool, fill = acceptable))+
  geom_histogram(stat="count")+
  ggtitle("Accuracy of Observations Stratified by Tool")

table(obs_rm$tool, obs_rm$acceptable)
```

We quanitatively assessed whether observations were supported by the data. This required translation of dietitian's written statements into conditional statements. 

We can see that 37 observations were unable to evaluted against the data and were not characterized as acceptable/unacceptable. Many of these were related to the ingredient composition of meals as examined using the HTML-based tool. 

The plot above demonstrates that the overall accuracy of observations was higher using the interactive tool (76.4% vs. 65.9%) 

```{r}
chisq.test(obs_rm$acceptable, obs_rm$tool)
```

Unfortunately, there were too little data for this difference to be statistically significant. 

#### Observations regarding glycemic response
```{r}
BG <- obs_rm %>% filter(type == 'BG')
chisq.test(BG$acceptable, BG$tool)

table(BG$acceptable, BG$tool)
```

Statements generated with the interactive tool regarding blood glucose changes *were not* more accurate than those generated with the HTML representation. (p = 0.81)

**Discussion:**

We knew that one of the limitations of the study was my failure to transform the macronutrient & glycemic data against a reference standard (eg. acceptable BG change is <115 or 20-35g carbohydrates/meal). This could certainly explain the lack of improvement in observations related specifically to glycemic response. 

SHINY may have improved understanding of general trends in blood glucose but not associations of BG change and macronutrients/mealtimes. In contrast, no observations generated using HTML contained an inference such as ‘dinner: BG change no peaks, they are average’

#### Observations regarding nutrition & macronutrient composition
```{r}
nutrition <- obs_rm %>% filter(type == 'Nutrition')
chisq.test(nutrition$acceptable, nutrition$tool)
table(nutrition$acceptable, nutrition$tool)
```

Statements generated with the interactive tool regarding nutrition/macronutrients *were* more accurate than those generated with the HTML representation. (p = 0.05)

## Comparing the quality of observations further

```{r}
ggplot(obs_rm[!is.na(obs_rm$tool) & !is.na(obs_rm$level), ], 
       aes(x = level, fill = acceptable))+
  geom_histogram(stat="count")+
  facet_grid(~tool)+
  ggtitle("Accuracy of Observations Stratified by Tool")
```

Again we can see that the majority of observations were related to macronutrients and/or blood glucose change. Most of the observations that we did not judge as acceptable/unacceptable related to ingredients of a specific meal / mealtypes (break, lunch, or dinner).
